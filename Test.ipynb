{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SigmoidActivationFunction:\n",
    "    \n",
    "    @staticmethod\n",
    "    def value(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative(z):\n",
    "        sig = SigmoidActivationFunction.value(z)\n",
    "        return sig * (1 - sig)\n",
    "    \n",
    "    \n",
    "class CrossEntropyCostFunction:\n",
    "\n",
    "    @staticmethod\n",
    "    def cost(actual, predicted, numberOfExamples):\n",
    "        return np.sum(np.nan_to_num(-actual * np.log(predicted).T - (1 - actual) * np.log(1 - predicted).T)) / numberOfExamples    \n",
    "    \n",
    "    @staticmethod\n",
    "    def regulazation(weightsList, lambdaFactor, numberOfelements):\n",
    "        cost = 0\n",
    "        for w in weightsList:\n",
    "            cost +=np.sum(w**2)\n",
    "        return (lambdaFactor/(2*numberOfelements))*cost\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def delta(actual, predicted, activationFunction):\n",
    "        return predicted-actual\n",
    "    \n",
    "    \n",
    "class WeightPacking:\n",
    "    @staticmethod\n",
    "    def unpack(weights, layerSizes):\n",
    "        requredLen = sum([y*x for y,x in layerSizes])\n",
    "        if requredLen == len(weights):\n",
    "            start = 0\n",
    "            returnList = []\n",
    "            for y,x in layerSizes:\n",
    "                returnList.append(weights[start:start+y*x].reshape((y,x)))\n",
    "                start +=y*x\n",
    "            return returnList\n",
    "        else:\n",
    "            raise ValueError(\"Weights sizes mismatch,\", requredLen, \"weights requred,\",len(weights) , \"recived\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def pack(weightsList):\n",
    "        return np.concatenate([w.ravel() for w in weightsList])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NN_1HL:\n",
    "    #opti_method='TNC' BFGS\n",
    "    def __init__(self, layerSizes = [50, 25], reg_lambda=0, epsilon_init=0.12, \n",
    "                 opti_method='TNC', maxiter=500,\n",
    "                 activationFunction = SigmoidActivationFunction,\n",
    "                 costFunction = CrossEntropyCostFunction, weightPacking=WeightPacking):\n",
    "        \n",
    "        self.epsilon_init = epsilon_init\n",
    "        self._method = opti_method\n",
    "        self._maxiter = maxiter\n",
    "        self._reg_lambda = reg_lambda\n",
    "        self._costFunction = costFunction\n",
    "        self._activationFunction = activationFunction\n",
    "        self._layerSizes = layerSizes\n",
    "        self._weightPacking = weightPacking\n",
    "    \n",
    "    def rand_init(self, l_in, l_out):\n",
    "        return np.random.randn(l_out, l_in + 1) * 2 * self.epsilon_init - self.epsilon_init\n",
    "           \n",
    "        \n",
    "    def unpackWeights(self, thetas, layers):\n",
    "        sizes = []\n",
    "        for x in range(len(layers)-1):\n",
    "            sizes.append((layers[x+1], layers[x] + 1))\n",
    "        ls = self._weightPacking.unpack(thetas, sizes)\n",
    "        return ls\n",
    "    \n",
    "    \n",
    "    def _forward(self, X, weights):\n",
    "        aList = [self.addOnes(X)]\n",
    "        zList = []\n",
    "        lastLayer = None\n",
    "        \n",
    "        for w in weights:\n",
    "            \n",
    "            z = np.dot(w, aList[-1].T)\n",
    "            a = self._activationFunction.value(z)\n",
    "            \n",
    "            aList.append(self.addOnes(a.T))\n",
    "            zList.append(z)\n",
    "            lastLayer = a\n",
    "            \n",
    "        return aList[0:-1], zList, lastLayer\n",
    "    \n",
    "    \n",
    "    def variableSetup(self, thetas, layers,  X, y):\n",
    "        weights = self.unpackWeights(thetas, layers)\n",
    "        m = X.shape[0]\n",
    "        Y = np.eye(layers[-1])[y]\n",
    "        return (weights, m, Y)\n",
    "        \n",
    "        \n",
    "    def removeBiasesFromWeightMatrices(self, listOfWeights):\n",
    "        return [w[:, 1:] for w in listOfWeights]\n",
    "    \n",
    "    \n",
    "    def function(self, thetas, layers,  X, y, reg_lambda):\n",
    "        #initial values setup\n",
    "        weights, m, Y = self.variableSetup(thetas, layers, X, y)\n",
    "        \n",
    "        #feedforward\n",
    "        aList, zList, prediction = self._forward(X, weights)\n",
    "\n",
    "        #error calculation\n",
    "        si = [self._costFunction.delta(Y, prediction.T, self._activationFunction)]\n",
    "        \n",
    "        #backpropagation\n",
    "        for x in range(len(zList)-1, 0, -1):\n",
    "            si.append((np.dot(si[-1], weights[x]) * self._activationFunction.derivative(self.addOnes(zList[x-1].T)))[:, 1:])\n",
    "\n",
    "        #delta calculation\n",
    "        Deltas = [np.dot(siN.T, aN) for siN, aN in zip(reversed(si), aList)]\n",
    "        \n",
    "        #gradient calculation\n",
    "        Theta_grads = [d/m for d in Deltas]\n",
    "        \n",
    "        tfs = self.removeBiasesFromWeightMatrices(weights)\n",
    "        \n",
    "        #cost\n",
    "        J = self._costFunction.cost(Y, prediction, m)\n",
    "        reg = 0 \n",
    "        \n",
    "        #regulazation calculation\n",
    "        if reg_lambda != 0:\n",
    "            reg = self._costFunction.regulazation(tfs, self._reg_lambda, m)\n",
    "            for x in range(len(Theta_grads)):\n",
    "                Theta_grads[x][:, 1:] += (reg_lambda / m) * tfs[x]\n",
    "\n",
    "        return (J + reg, Theta_grads)\n",
    "    \n",
    "    \n",
    "    def functionOpt(self, thetas, layers, X, y, reg_lambda):\n",
    "        c, dw = self.function(thetas, layers, X, y, reg_lambda)\n",
    "        return (c, self._weightPacking.pack(dw))\n",
    "    \n",
    "    \n",
    "    def addOnes(self, x):\n",
    "        ys,xs = x.shape\n",
    "        z = np.ones((ys,1))\n",
    "        return np.concatenate((z, x), axis=1)\n",
    "    \n",
    "    \n",
    "    def generateWeights(self, inputLayerSize, layerSizes, numLabels):\n",
    "        ls = [self.rand_init(inputLayerSize, layerSizes[0])]\n",
    "        for x in range(0, len(layerSizes)-1):\n",
    "            ls.append(self.rand_init(layerSizes[x], layerSizes[x+1]))\n",
    "        ls.append(self.rand_init(layerSizes[-1], numLabels))\n",
    "        return ls\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        num_features = X.shape[0]\n",
    "        input_layer_size = X.shape[1]\n",
    "        num_labels = len(set(y))\n",
    "        \n",
    "        #return list of weights\n",
    "        weights = self.generateWeights(input_layer_size, self._layerSizes, num_labels)\n",
    "\n",
    "        \n",
    "        layers = [input_layer_size] + self._layerSizes + [num_labels]\n",
    "        \n",
    "        args = (layers, X, y, self._reg_lambda)\n",
    "        \n",
    "        options = {'maxiter': self._maxiter}\n",
    "        _res = optimize.minimize(self.functionOpt, self._weightPacking.pack(weights), jac=True, method=self._method, \n",
    "                                 args=args, options=options)\n",
    "        \n",
    "        self.weights = self.unpackWeights(_res.x, layers)\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X).argmax(0)\n",
    "    \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        _, _, h = self._forward(X, self.weights)\n",
    "        return h\n",
    "    \n",
    "    def getWeights(self):\n",
    "        return self.weights\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 400)\n",
      "(50, 401)\n",
      "(20, 51)\n",
      "(10, 21)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "data = loadmat('ex3data1.mat')\n",
    "np.random.seed(40)\n",
    "X, y = data['X'], data['y']\n",
    "y = y.reshape(X.shape[0])\n",
    "y = y - 1  # Fix notation # TODO: Automaticlly fix that on the class\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "nn = NN_1HL(layerSizes=[50, 20], maxiter=100, reg_lambda=1)\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_test, nn.predict(X_test))\n",
    "print(X.shape)\n",
    "for x in nn.getWeights():\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.85733333333333328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4)\n",
    "nn = NN_1HL(layerSizes=[50, 30], maxiter=100, reg_lambda=1)\n",
    "nn.fit(X_train, y_train)\n",
    "accuracy_score(y_test, nn.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "0.96666666666666667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.52817684  0.32312065]\n",
      " [ 0.80975388  0.06100429]\n",
      " [ 0.94629727  0.25635086]]\n",
      "\n",
      "[[ 0.95200163  0.35435641  0.22840884  0.16440801]\n",
      " [ 0.86332623  0.69000625  0.90245113  0.33116605]]\n",
      "\n",
      "[[ 0.53626987  0.46399028]\n",
      " [ 0.47600067  0.11168056]\n",
      " [ 0.41924697  0.14158498]\n",
      " [ 0.95637804  0.03635139]\n",
      " [ 0.58220501  0.811917  ]]\n",
      "\n",
      "[ 0.52817684  0.32312065  0.80975388  0.06100429  0.94629727  0.25635086\n",
      "  0.95200163  0.35435641  0.22840884  0.16440801  0.86332623  0.69000625\n",
      "  0.90245113  0.33116605  0.53626987  0.46399028  0.47600067  0.11168056\n",
      "  0.41924697  0.14158498  0.95637804  0.03635139  0.58220501  0.811917  ]\n",
      "\n",
      "[[ 0.52817684  0.32312065]\n",
      " [ 0.80975388  0.06100429]\n",
      " [ 0.94629727  0.25635086]]\n",
      "[[ 0.95200163  0.35435641  0.22840884  0.16440801]\n",
      " [ 0.86332623  0.69000625  0.90245113  0.33116605]]\n",
      "[[ 0.53626987  0.46399028]\n",
      " [ 0.47600067  0.11168056]\n",
      " [ 0.41924697  0.14158498]\n",
      " [ 0.95637804  0.03635139]\n",
      " [ 0.58220501  0.811917  ]]\n"
     ]
    }
   ],
   "source": [
    "w1 = np.random.rand(3,2)\n",
    "w2 = np.random.rand(2,4)\n",
    "w3 = np.random.rand(5,2)\n",
    "print(w1)\n",
    "print(\"\")\n",
    "print(w2)\n",
    "print(\"\")\n",
    "print(w3)\n",
    "print(\"\")\n",
    "x = np.concatenate([w1.ravel(),w2.ravel(),w3.ravel()])\n",
    "print(x)\n",
    "\n",
    "sizes = [(3,2),(2,4),(5,2)]\n",
    "print(\"\")\n",
    "def neki(sizes, weights):\n",
    "    if sum([y*x for y,x in sizes]) == len(weights):\n",
    "        start = 0\n",
    "        for y,x in sizes:\n",
    "            print(weights[start:start+y*x].reshape((y,x)))\n",
    "            start +=y*x\n",
    "    else:\n",
    "        print(\"error\")\n",
    "    \n",
    "\n",
    "neki(sizes, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x**2+15*x\n",
    "\n",
    "def fd(x):\n",
    "    return (x**2+15*x, 2*x+15)\n",
    "\n",
    "\n",
    "optimize.minimize(fd, 100, jac = True).x"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
