{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SigmoidActivationFunction:\n",
    "    \n",
    "    @staticmethod\n",
    "    def value(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative(z):\n",
    "        sig = SigmoidActivationFunction.value(z)\n",
    "        return sig * (1 - sig)\n",
    "    \n",
    "class WeightPacking:\n",
    "    @staticmethod\n",
    "    def pack(weights, biases):\n",
    "        return np.concatenate([np.concatenate((b.T, w.T), 1).reshape(-1) for w,b in zip(weights, biases)])\n",
    "    \n",
    "    @staticmethod\n",
    "    def unpack(thetas, layers):\n",
    "        start = 0\n",
    "        weights = []\n",
    "        biases = []\n",
    "        for x in range(len(layers)-1):\n",
    "            Wlen = layers[x+1] * (layers[x] + 1)\n",
    "            W = thetas[start:start+Wlen].reshape((layers[x+1], layers[x] + 1))\n",
    "            start += Wlen\n",
    "            weights.append(W[:, 1:].T)\n",
    "            biases.append(W[:, 0][np.newaxis])\n",
    "        return weights, biases\n",
    "    \n",
    "    \n",
    "class CrossEntropyCostFunction:\n",
    "    @staticmethod\n",
    "    def cost(actual, predicted):\n",
    "        return np.sum(np.nan_to_num(-actual * np.log(predicted) - (1 - actual) * np.log(1 - predicted)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def delta(actual, predicted, activationFunction):\n",
    "        return predicted-actual\n",
    "    \n",
    "class WeightInitializationRandom:\n",
    "    def __init__(self, epsilon_init):\n",
    "        self.eps = epsilon_init\n",
    "    \n",
    "    def Initialize(self, l_in, l_out):\n",
    "        w = np.random.rand(l_out, l_in + 1) * 2 * self.eps - self.eps\n",
    "        tw = w[:, 1:].T\n",
    "        tb = w[:, 0][np.newaxis]\n",
    "        return (tw,tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NN_1HL(object):\n",
    "    \n",
    "    def __init__(self, WeightInitialization, reg_lambda=0,\n",
    "                 hidden_layer_size=[30, 20], opti_method='TNC', maxiter=500, \n",
    "                 ActivationFunction = SigmoidActivationFunction, CostFunction = CrossEntropyCostFunction):\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.activation_func = ActivationFunction.value\n",
    "        self.activation_func_prime = ActivationFunction.derivative\n",
    "        self.method = opti_method\n",
    "        self.maxiter = maxiter\n",
    "        self._CostFunction = CostFunction.cost\n",
    "        self._CostFunctionDelta = CostFunction.delta\n",
    "        self._WeightInitialization = WeightInitialization\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X).argmax(0)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        a, z = self._forward(X, self.weights, self.biases)\n",
    "        return a[-1].T\n",
    "    \n",
    "    def _forward(self, X, weights, biases):\n",
    "       \n",
    "        a = [X]\n",
    "        z = []\n",
    "        for w,b in zip(weights, biases):\n",
    "            z.append(np.dot(a[-1], w) + b)\n",
    "            a.append(self.activation_func(z[-1]))\n",
    "        return a,z\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        num_features = X.shape[0]\n",
    "        input_layer_size = X.shape[1]\n",
    "        num_labels = len(set(y))\n",
    "\n",
    "        \n",
    "        tw = []\n",
    "        tb = []\n",
    "        layers = [input_layer_size] + self.hidden_layer_size + [num_labels]\n",
    "        for l in range(len(layers)-1):\n",
    "            w, b = self._WeightInitialization.Initialize(layers[l], layers[l+1])\n",
    "            tw.append(w)\n",
    "            tb.append(b)\n",
    "\n",
    "        thetas0 = WeightPacking.pack(tw, tb)\n",
    "\n",
    "        options = {'maxiter': self.maxiter}\n",
    "        _res = optimize.minimize(self.function, thetas0, jac=True, method=self.method, \n",
    "                                 args=(layers, X, y, self.reg_lambda), options=options)\n",
    "        \n",
    "        self.weights, self.biases = WeightPacking.unpack(_res.x, layers)\n",
    "    \n",
    "    \n",
    "    def function(self, thetas, layers, X, y, reg_lambda):\n",
    "        \n",
    "        #Varible setup\n",
    "        m = X.shape[0]\n",
    "        Y = np.eye(layers[-1])[y]\n",
    "        wk, bk = WeightPacking.unpack(thetas, layers)\n",
    "\n",
    "        #Forward\n",
    "        a, z = self._forward(X, wk, bk)\n",
    "        \n",
    "        #Cost\n",
    "        J = self._CostFunction(Y, a[-1]) / m\n",
    "\n",
    "        \n",
    "        \n",
    "        D3 = (a[3] - Y)\n",
    "        ThetaGradW2 = np.dot(a[2].T, D3)/m\n",
    "        \n",
    "        D2 = np.dot(D3, wk[2].T) * self.activation_func_prime(z[1])\n",
    "        ThetaGradW1 = np.dot(a[1].T, D2)/m\n",
    "        \n",
    "        D1 = np.dot(D2, wk[1].T) * self.activation_func_prime(z[0])\n",
    "        ThetaGradW0 = np.dot(a[0].T, D1)/m\n",
    "\n",
    "        ThetaGradB0 = np.mean(D1, 0)[np.newaxis]\n",
    "        ThetaGradB1 = np.mean(D2, 0)[np.newaxis]\n",
    "        ThetaGradB2 = np.mean(D3, 0)[np.newaxis]\n",
    "\n",
    "        if reg_lambda != 0:\n",
    "            J += self.reg_lambda / (2 * m) * np.sum([np.sum(w**2) for w in wk])\n",
    "            ThetaGradW0 += (reg_lambda / m) * wk[0]\n",
    "            ThetaGradW1 += (reg_lambda / m) * wk[1]\n",
    "            ThetaGradW2 += (reg_lambda / m) * wk[2]\n",
    "        return (J,  WeightPacking.pack([ThetaGradW0, ThetaGradW1, ThetaGradW2], [ThetaGradB0, ThetaGradB1, ThetaGradB2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93333333333333335"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})\n",
    "np.random.seed(40)\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn import cross_validation\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "winit = WeightInitializationRandom(0.12)\n",
    "nn = NN_1HL(WeightInitialization = winit, reg_lambda = 0.1, maxiter=500)#maxiter=0\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, nn.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.96666666666666667 #[25], reg = 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.876"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(40)\n",
    "from scipy.io import loadmat\n",
    "data = loadmat('ex3data1.mat')\n",
    "X, y = data['X'], data['y']\n",
    "y = y.reshape(X.shape[0], )\n",
    "y = y - 1  # Fix notation # TODO: Automaticlly fix that on the class\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "winit = WeightInitializationRandom(0.12)\n",
    "nn = NN_1HL(winit, maxiter=50, reg_lambda = 2.1)\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_test, nn.predict(X_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.876"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8536125\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from scipy.io import loadmat\n",
    "data = loadmat('ex3data1.mat')\n",
    "X, y = data['X'], data['y']\n",
    "\n",
    "#X += np.abs(np.min(X))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#X = min_max_scaler.fit_transform(X)\n",
    "#X = (X + np.abs(np.min(X))) / (np.max(X) + np.abs(np.min(X)))\n",
    "#print(np.min(X), np.max(X))\n",
    "\n",
    "y = y.reshape(X.shape[0], )\n",
    "y = y - 1  # Fix notation # TODO: Automaticlly fix that on the class\n",
    "\n",
    "trialsList = []\n",
    "winit = WeightInitializationRandom(0.12)\n",
    "for trials in range(200):\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.4)\n",
    "    nn = NN_1HL(winit, maxiter=50, reg_lambda = 2.1)\n",
    "    nn.fit(X_train, y_train)\n",
    "    trialsList.append(accuracy_score(y_test, nn.predict(X_test)))\n",
    "print(np.mean(trialsList))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no min max: 0.860855\n",
    "min max: 0.803995\n",
    "min max whole matrix: 0.8357325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16531 0.16531 0.16531 ..., 0.16532 0.16531 0.16531]\n",
      " [0.12314 0.12314 0.12314 ..., 0.12314 0.12314 0.12314]\n",
      " [0.10187 0.10187 0.10187 ..., 0.10188 0.10187 0.10187]\n",
      " ..., \n",
      " [0.14059 0.14059 0.14059 ..., 0.14060 0.14059 0.14059]\n",
      " [0.14721 0.14721 0.14721 ..., 0.14721 0.14721 0.14721]\n",
      " [0.10188 0.10188 0.10188 ..., 0.10189 0.10188 0.10188]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1,1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=4, init='nndsvdar', random_state=0)\n",
    "#model.fit(X).gcomponents_\n",
    "#print(X_train + np.abs(np.min(X_train)))\n",
    "W = model.fit_transform(X_train + np.abs(np.min(X_train)))\n",
    "H = model.components_\n",
    "\n",
    "#print(W.shape)\n",
    "#print(H.T)\n",
    "#print(np.max(X_train))\n",
    "\n",
    "print(np.dot(W, H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50000, 0.00000, 1.00000],\n",
       "       [1.00000, 0.50000, 0.40000],\n",
       "       [0.00000, 1.00000, 0.00000]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
