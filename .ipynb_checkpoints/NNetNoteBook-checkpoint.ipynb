{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "def readDataAndLabels(fileName):\n",
    "    train = genfromtxt(fileName, delimiter=',', dtype=float, skip_header=1)\n",
    "    return (train[:, 0], train[:, 1:])\n",
    "\n",
    "def oneHot(array):\n",
    "    m = np.max(array)\n",
    "    ar = np.zeros((len(array), m+1))\n",
    "    y=0\n",
    "    for x in array:\n",
    "        ar[y, x] = 1\n",
    "        y+=1\n",
    "    return ar\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SigmoidActivationFunction:\n",
    "    def value(self, x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "    def derivative(self, x):\n",
    "        v = self.value(x)\n",
    "        return np.multiply(v, 1-v)\n",
    "\n",
    "class NeuralNet:\n",
    "    def __init__(self, layerSizes, activationFunction):\n",
    "        self._layerSizes = layerSizes\n",
    "        self._activationFunction = activationFunction\n",
    "        self.initRandomWeights()\n",
    "        \n",
    "    def initRandomWeights(self):\n",
    "        self._weights = []\n",
    "        for layer in range(len(self._layerSizes)-1):\n",
    "            self._weights.append(np.random.randn(self._layerSizes[layer], self._layerSizes[layer+1]))\n",
    "        \n",
    "        self._biases = []\n",
    "        for bias in range(len(self._layerSizes)-1):\n",
    "            self._biases.append(np.random.randn(1, self._layerSizes[bias+1]))\n",
    "            \n",
    "    def getWeights(self):\n",
    "        return self._weights\n",
    "    \n",
    "    def setWeights(self, weights, biases):\n",
    "        self._weights = weights\n",
    "        self._biases = biases\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for weight, biases in zip(self._weights, self._biases):\n",
    "            X = self._activationFunction.value(X.dot(weight) + biases)\n",
    "        return X\n",
    "    \n",
    "    def backpropagation(self, X, Y, costFunction):\n",
    "        pred = self.forward(X)\n",
    "        error = costFunction.cost(pred, Y.astype(float))\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{align}\n",
    "J\n",
    "&= \\left[ \\frac{1}{m} \\sum_{i=1}^m \\left( \\frac{1}{2} \\left\\| h_{W,b}(x^{(i)}) - y^{(i)} \\right\\|^2 \\right) \\right]\n",
    "                       + \\frac{\\lambda}{2} \\sum_{l=1}^{n_l-1} \\; \\sum_{i=1}^{s_l} \\; \\sum_{j=1}^{s_{l+1}} \\left( W^{(l)}_{ji} \\right)^2\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MSECost:\n",
    "    def cost(self, predicted, actual):\n",
    "        return 0.5 * np.sum(np.power(predicted - actual, 2))/len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datalabels, datapixels = readDataAndLabels('Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.08344196372\n"
     ]
    }
   ],
   "source": [
    "neuralNetwork = NeuralNet([784, 25, 10], SigmoidActivationFunction())\n",
    "pr = neuralNetwork.forward(datapixels/255)\n",
    "actual = oneHot(datalabels.astype(int))\n",
    "neuralNetwork.backpropagation(datapixels/255, actual, MSECost())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class Network(object):\n",
    "#\n",
    "#    def __init__(self, sizes):\n",
    "#        self.num_layers = len(sizes)\n",
    "#        self.sizes = sizes\n",
    "#        self.large_weight_initializer()\n",
    "#\n",
    "#    def large_weight_initializer(self):\n",
    "#        self.biases = [np.random.randn(y, 1) for y in self.sizes[1:]]\n",
    "#        self.weights = [np.random.randn(y, x)\n",
    "#                        for x, y in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "#    def feedforward(self, a):\n",
    "#        for b, w in zip(self.biases, self.weights):\n",
    "#            a = np.dot(w, a)\n",
    "#            print(a.shape)\n",
    "#        return a\n",
    "#        \n",
    "#n = Network([784, 25, 10])\n",
    "#n.feedforward(datapixels.transpose())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#oneHot(np.array([0,4,3,4,2,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.random.rand(3,2)\n",
    "B = np.random.rand(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6507183 ,  0.28288074],\n",
       "       [ 0.05034054,  0.98877129],\n",
       "       [ 0.41899786,  0.75450607]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.97621369,  0.6617447 ],\n",
       "       [ 0.90703541,  0.88849807],\n",
       "       [ 0.20557865,  0.38961472]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39071981001258638"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((A-B)**2)/len(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39071981001258638"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.sum((A-B)**2, 1))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
